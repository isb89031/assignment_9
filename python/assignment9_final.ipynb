{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db00f08",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml  #using openml to import data\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV      \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier  # added classification model\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier  # added classification model\n",
    "from sklearn.gaussian_process.kernels import RBF  # added classification model\n",
    "from sklearn.svm import LinearSVC  # added classification model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer #transform different types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38574613",
   "metadata": {},
   "source": [
    "## Load titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003556be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_initial, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "combine_dataset = pd.concat([X_initial, y], axis=1)\n",
    "combine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811453e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset for R\n",
    "combine_dataset.to_csv('./data/titanic_openml.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a006ab",
   "metadata": {},
   "source": [
    "## Part 1. Extend results with more variables\n",
    "\n",
    "### Add the variable that was in created in the previous analysis (Practice 7) - family size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dataset['family size'] = combine_dataset['sibsp'] + combine_dataset['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615c36f",
   "metadata": {},
   "source": [
    "### Pipelines: Pre-Processing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'fare', 'embarked', 'sex', 'pclass', 'family size']\n",
    "X = combine_dataset[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'fare', 'family size']  # family size added as new numerical feature/variable\n",
    "\n",
    "# Applying SimpleImputer and StandardScaler into a pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "\n",
    "# Applying SimpleImputer and then OneHotEncoder into another pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "data_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer, numerical_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dde5c4",
   "metadata": {},
   "source": [
    "### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbd7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d216d26",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8237b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'data_transformer__numerical__imputer__strategy': ['mean', 'median'],\n",
    "    'data_transformer__categorical__imputer__strategy': ['constant','most_frequent']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb86398",
   "metadata": {},
   "source": [
    "### Extend the results: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                          ('pipe_lr', LogisticRegression(max_iter=10000, penalty='none'))]) #penalty='l2' is default\n",
    "\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid=param_grid)\n",
    "grid_lr.fit(X_train, y_train);\n",
    "\n",
    "# Reference -- https://www.statisticshowto.com/regularization/\n",
    "# L1 regularization adds an L1 penalty equal to the absolute value of the magnitude of coefficients. Lasso regression uses this method.\n",
    "# L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients. Ridge regression uses this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5a607",
   "metadata": {},
   "source": [
    "### Extend the results: gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a4ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gdb = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "       ('pipe_gdb',GradientBoostingClassifier(random_state=2))])\n",
    "\n",
    "grid_gdb = GridSearchCV(pipe_gdb, param_grid=param_grid)\n",
    "grid_gdb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9aa56",
   "metadata": {},
   "source": [
    "## 2. Extend the results with other classification methods\n",
    "\n",
    "The following classification methods that are not demonstrated in the lecture:\n",
    "\n",
    "* Penalised logistic regression\n",
    "* Classification trees\n",
    "* Random forests\n",
    "* Gaussian process classification\n",
    "* Support vector machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7799d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalised logistic regression\n",
    "pipe_plr = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_plr', LogisticRegression(penalty='l1', max_iter=10000, tol=0.01, solver='saga'))])\n",
    "grid_plr = GridSearchCV(pipe_plr, param_grid=param_grid)\n",
    "grid_plr.fit(X_train, y_train);\n",
    "\n",
    "# Reference -- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# tol=0.01 -- tolerance for stopping criteria; stop searching for a minimum (or maximum) once some tolerance is achieved\n",
    "# solver='saga' -- algorithm to use in the optimization problem; 'sag' and 'saga' are faster for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification tree\n",
    "pipe_tree = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_tree', DecisionTreeClassifier(random_state=0))])\n",
    "grid_tree = GridSearchCV(pipe_tree, param_grid=param_grid)\n",
    "grid_tree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128de939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "pipe_rf = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_rf', RandomForestClassifier(random_state=0))])\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid=param_grid)\n",
    "grid_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian process classification\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "pipe_gp = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                          ('pipe_gp',  GaussianProcessClassifier(kernel=kernel, random_state=0))])\n",
    "grid_gp = GridSearchCV(pipe_gp, param_grid=param_grid)\n",
    "grid_gp.fit(X_train, y_train);\n",
    "\n",
    "# References:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html\n",
    "# https://machinelearningmastery.com/gaussian-processes-for-classification-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machines\n",
    "pipe_svm = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_svm',  LinearSVC(random_state=0, max_iter=10000, tol=0.01))])\n",
    "grid_svm = GridSearchCV(pipe_svm, param_grid=param_grid)\n",
    "grid_svm.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machines (with additional hyperparameter tuning)\n",
    "# Note: LinearSVC generates a linear classifier, while SVC lets you choose non-linear kernels\n",
    "\n",
    "pipe_svc = Pipeline(steps=[('data_transformer', data_transformer),\n",
    "                           ('pipe_svc',  SVC())])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid2 = param_grid.copy()  #copy and extend param_grid\n",
    "param_grid2['pipe_svc__kernel']=['rbf', 'poly','sigmoid']\n",
    "param_grid2['pipe_svc__C']=[0.1, 1, 10]\n",
    "\n",
    "#Alternatively, you can use '**' to pass multiple arguments to a function directly using a dictionary\n",
    "#param_grid2 = { **param_grid,\n",
    "#               'pipe_svc__kernel':['rbf', 'poly','sigmoid'],\n",
    "#               'pipe_svc__C':[0.1, 1, 10]\n",
    "#              }\n",
    "                        \n",
    "grid_svc = GridSearchCV(pipe_svc, param_grid=param_grid2)\n",
    "grid_svc.fit(X_train, y_train);\n",
    "\n",
    "grid_svc.best_params_\n",
    "#grid_svc.best_estimator_\n",
    "#grid_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f8f1a",
   "metadata": {},
   "source": [
    "## Compare performance of classification models by the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518896a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(8,8))\n",
    "ax = plt.gca()\n",
    "\n",
    "plot_roc_curve(grid_lr, X_test, y_test, ax=ax, name='Logistic Regression')\n",
    "plot_roc_curve(grid_plr, X_test, y_test, ax=ax, name='Penalised logistic regression')\n",
    "plot_roc_curve(grid_gdb, X_test, y_test, ax=ax, name='Gradient Boosting')\n",
    "plot_roc_curve(grid_tree, X_test, y_test, ax=ax, name='Classification trees')\n",
    "plot_roc_curve(grid_rf, X_test, y_test, ax=ax, name='Random forests')\n",
    "plot_roc_curve(grid_gp, X_test, y_test, ax=ax, name='Gaussian process classification')\n",
    "plot_roc_curve(grid_svm, X_test, y_test, ax=ax, name='Support vector machines (LinearSVC)')\n",
    "plot_roc_curve(grid_svc, X_test, y_test, ax=ax, name='Support vector machines (SVC)')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
